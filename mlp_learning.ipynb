{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-layer NN learning + basis functions visualization\n",
    "\n",
    "Author: Teun Mathijssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"Target function.\"\"\"\n",
    "#     return x*np.cos(1.5 * x)\n",
    "#     return np.heaviside(x, 0.5)\n",
    "    return np.abs(x)\n",
    "#     return np.sin(x)\n",
    "\n",
    "\n",
    "def h(x):\n",
    "    \"\"\"Activation function.\"\"\"\n",
    "    # ReLU\n",
    "#     return np.select([x < 0, x >= 0], [0, x])\n",
    "    # Tanh\n",
    "    return np.tanh(x)\n",
    "    # Sigmoid\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def h_p(x):\n",
    "    \"\"\"Derivative of activation function.\"\"\"\n",
    "    # ReLU\n",
    "#     return np.select([x < 0, x >= 0], [0, 1])\n",
    "    # Tanh\n",
    "    return 1 - np.tanh(x)**2\n",
    "    # Sigmoid\n",
    "#     return (1/(1 + np.exp(-x)))*(1 - 1/(1 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_propagate(t, x, W_1, w_2, lamb):\n",
    "    \"\"\"Propagate batch x through our 2-layer NN using h(x) as activation function.\n",
    "    Return output, batch derivatives and hidden layer output.\"\"\"\n",
    "    # Propagate forward.\n",
    "    # Augment x.\n",
    "    x_ = np.vstack((np.ones((1, x.shape[-1])), x))\n",
    "    \n",
    "    a = W_1 @ x_\n",
    "\n",
    "    z = h(a)\n",
    "    # Augment z.\n",
    "    z_ = np.vstack((np.ones((1, z.shape[-1])), z))\n",
    "    \n",
    "    y = w_2 @ z_\n",
    "    \n",
    "    # Propagate backward.\n",
    "    dy = y - t\n",
    "    \n",
    "    # Infer batch size for quadratic regularization.\n",
    "    bs = t.size\n",
    "    \n",
    "    # Use numpy's superior broadcasting capabilities to calculate all\n",
    "    # derivatives at once and sum them.\n",
    "    dE_dw_2_batch = dy[:, np.newaxis] * z_[np.newaxis]\n",
    "    dE_dw_2 = np.sum(dE_dw_2_batch, axis=-1) + bs*lamb*w_2\n",
    "    \n",
    "    # We don't need dz_0.\n",
    "    dz = h_p(a) * (w_2.T @ dy)[1:]\n",
    "    \n",
    "    dE_dW_1_batch = dz[:, np.newaxis] * x_[np.newaxis]\n",
    "    dE_dW_1 = np.sum(dE_dW_1_batch, axis=-1) + bs*lamb*W_1\n",
    "        \n",
    "    return np.squeeze(y), dE_dw_2, dE_dW_1, z_\n",
    "\n",
    "\n",
    "def SGD(ts, xs, W_1, w_2, lamb=1e-4, nEpochs=1000, lr=0.003, bs=2, plotBase=10):\n",
    "    \"\"\"Perform SGD and plot the results.\"\"\"\n",
    "    if xs.shape[-1] % bs != 0:\n",
    "        print(\"Error: batch size must divide input size.\")\n",
    "        return\n",
    "    \n",
    "    # List of all epoch numbers.\n",
    "    epochs = np.arange(0, nEpochs + 1)\n",
    "    \n",
    "    # 0 epoch prediction and error.\n",
    "    ys, _, _, z_ = NN_propagate(ts, xs, W_1, w_2, lamb)\n",
    "    errors_plot = [np.sum((ys - ts)**2) / 2]\n",
    "    epochs_plot = [epochs[0]]\n",
    "    plot_data(epochs[0], xs, ys, ts, z_, w_2)\n",
    "    \n",
    "    # SGD.\n",
    "    for curEpoch in epochs[1:]:\n",
    "        # Shuffle inputs and targets.\n",
    "        indices_random = np.arange(N)\n",
    "        np.random.shuffle(indices_random)\n",
    "        xs_random = xs[indices_random]\n",
    "        ts_random = ts[indices_random]\n",
    "\n",
    "        # Process batches.\n",
    "        for b in np.arange(0, N, bs):\n",
    "            _, dE_dw_2, dE_dW_1, z_ = NN_propagate(ts_random[b:b+bs], xs_random[b:b+bs], W_1, w_2, lamb)\n",
    "            W_1 = W_1 - lr * dE_dW_1\n",
    "            w_2 = w_2 - lr * dE_dw_2\n",
    "                            \n",
    "        # Use logarithmic epoch intervals for plotting.\n",
    "        if curEpoch % plotBase ** np.floor(np.log(curEpoch) / np.log(plotBase)) == 0 or curEpoch == nEpochs:\n",
    "            # Current epoch prediction and error.\n",
    "            ys, _, _, z_ = NN_propagate(ts, xs, W_1, w_2, lamb)\n",
    "            errors_plot.append(np.sum((ys - ts)**2) / 2)\n",
    "            epochs_plot.append(curEpoch)\n",
    "            plot_data(curEpoch, xs, ys, ts, z_, w_2)\n",
    "    \n",
    "    plot_errors(epochs_plot, errors_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(curEpoch, xs, ys, ts, z_, w_2):\n",
    "    \"\"\"Plot current epoch output layer and hidden layer.\"\"\"\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(xs, ts, color=\"lightgray\", marker=\"o\", markersize=4, linestyle=\"\")\n",
    "    plt.plot(xs, ys, color=\"black\", marker=\"o\", markersize=4, linewidth=1)\n",
    "    plt.ylim((-1.2, 1.2))\n",
    "    plt.title(\"Output epoch \" + str(curEpoch))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i in range(len(z_)):\n",
    "        plt.plot(xs, w_2[:, i] * z_[i], linestyle=(0, (2, np.random.randint(5, 8))))\n",
    "    plt.title(\"Hidden layer output\")\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.12, hspace=0, top=1, bottom=0)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_errors(epochs_plot, errors_plot):\n",
    "    \"\"\"Plot error vs. epoch on log-log scale.\"\"\"\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    \n",
    "    plt.plot(epochs_plot, errors_plot, color=\"red\", marker=\"x\", markersize=6, linewidth=1)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"E\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.grid()\n",
    "    plt.title(\"Error vs. epoch\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of data points.\n",
    "N = 50\n",
    "\n",
    "# Input layer.\n",
    "D = 1\n",
    "# Hidden layer.\n",
    "M = 3\n",
    "# Output layer.\n",
    "K = 1\n",
    "\n",
    "# (Input)-(hidden layer) weight matrix.\n",
    "W_1 = np.random.normal(0, 0.3, (M, D+1))\n",
    "\n",
    "# (Hidden layer)-(output) weight matrix.\n",
    "w_2 = np.random.normal(0, 0.3, (K, M+1))\n",
    "\n",
    "# Input and target.\n",
    "xs = np.linspace(-math.pi, math.pi, N)\n",
    "ts = f(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running instructions\n",
    "\n",
    "Keep the output of the cell below expanded and press `shift + enter` to see the plots as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SGD(ts, xs, W_1, w_2, lamb=0, nEpochs=10000, lr=0.003, bs=5, plotBase=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
